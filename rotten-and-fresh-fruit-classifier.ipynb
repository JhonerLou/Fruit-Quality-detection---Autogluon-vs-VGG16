{"cells":[{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset restructuring and splitting completed.\n"]}],"source":["import os\n","import shutil\n","import random\n","\n","# Original folder structure\n","base_path = r\"C:\\Users\\acer\\Downloads\\Processed Images_Fruits\"\n","output_path = r\"C:\\Users\\acer\\Downloads\\dataset dummy\"\n","\n","# Define qualities and fruits\n","qualities = [\"good quality\", \"mixed quality\", \"bad quality\"]\n","fruits = [\"Orange\", \"Apple\", \"Banana\", \"Guava\", \"Lime\", \"Pomegranate\"]  # Add more fruit names here\n","\n","# Split ratio (90% for train, 10% for validation)\n","split_ratio = 0.9\n","\n","# Create the new structure for train and validation\n","for quality in qualities:\n","    for fruit in fruits:\n","        # Create directories for train and validation\n","        os.makedirs(os.path.join(output_path, \"train\", f\"{quality.replace(' ', '_')}_{fruit}\"), exist_ok=True)\n","        os.makedirs(os.path.join(output_path, \"validation\", f\"{quality.replace(' ', '_')}_{fruit}\"), exist_ok=True)\n","\n","# Move files into the new structure (train/validation)\n","for quality in qualities:\n","    quality_path = os.path.join(base_path, quality)\n","    for fruit in fruits:\n","        fruit_path = os.path.join(quality_path, fruit)\n","        train_folder = os.path.join(output_path, \"train\", f\"{quality.replace(' ', '_')}_{fruit}\")\n","        valid_folder = os.path.join(output_path, \"validation\", f\"{quality.replace(' ', '_')}_{fruit}\")\n","\n","        if os.path.exists(fruit_path):\n","            files = os.listdir(fruit_path)\n","            random.shuffle(files)\n","            \n","            # Split files\n","            train_files = files[:int(len(files) * split_ratio)]\n","            valid_files = files[int(len(files) * split_ratio):]\n","            \n","            # Move train files\n","            for img_file in train_files:\n","                src_file = os.path.join(fruit_path, img_file)\n","                dst_file = os.path.join(train_folder, img_file)\n","                shutil.copy(src_file, dst_file)\n","            \n","            # Move validation files\n","            for img_file in valid_files:\n","                src_file = os.path.join(fruit_path, img_file)\n","                dst_file = os.path.join(valid_folder, img_file)\n","                shutil.copy(src_file, dst_file)\n","\n","print(\"Dataset restructuring and splitting completed.\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.221295Z","iopub.status.busy":"2024-12-21T05:57:43.220822Z","iopub.status.idle":"2024-12-21T05:57:43.522005Z","shell.execute_reply":"2024-12-21T05:57:43.521219Z","shell.execute_reply.started":"2024-12-21T05:57:43.221251Z"},"trusted":true},"outputs":[],"source":["\n","import tensorflow\n","\n","from tensorflow import keras\n","\n","base_model = keras.applications.VGG16(\n","    weights='imagenet',\n","    input_shape=(224, 224, 3),\n","    include_top=False)"]},{"cell_type":"markdown","metadata":{},"source":["Freeze Base Model\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.523480Z","iopub.status.busy":"2024-12-21T05:57:43.523223Z","iopub.status.idle":"2024-12-21T05:57:43.527878Z","shell.execute_reply":"2024-12-21T05:57:43.526904Z","shell.execute_reply.started":"2024-12-21T05:57:43.523456Z"},"trusted":true},"outputs":[],"source":["base_model.trainable = False"]},{"cell_type":"markdown","metadata":{},"source":["Add New Layers\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.530173Z","iopub.status.busy":"2024-12-21T05:57:43.529817Z","iopub.status.idle":"2024-12-21T05:57:43.595898Z","shell.execute_reply":"2024-12-21T05:57:43.595201Z","shell.execute_reply.started":"2024-12-21T05:57:43.530136Z"},"trusted":true},"outputs":[],"source":["inputs = keras.Input(shape=(224, 224, 3))\n","\n","x = base_model(inputs, training=False)\n","\n","#pooling layer \n","x = keras.layers.GlobalAveragePooling2D()(x)\n","\n","#final dense layer\n","outputs = keras.layers.Dense(18, activation='softmax')(x)\n","\n","\n","model = keras.Model(inputs,outputs)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.597813Z","iopub.status.busy":"2024-12-21T05:57:43.597418Z","iopub.status.idle":"2024-12-21T05:57:43.604839Z","shell.execute_reply":"2024-12-21T05:57:43.603430Z","shell.execute_reply.started":"2024-12-21T05:57:43.597758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," global_average_pooling2d_2  (None, 512)               0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n"," dense_2 (Dense)             (None, 18)                9234      \n","                                                                 \n","=================================================================\n","Total params: 14723922 (56.17 MB)\n","Trainable params: 9234 (36.07 KB)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Compile the model"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.606650Z","iopub.status.busy":"2024-12-21T05:57:43.606287Z","iopub.status.idle":"2024-12-21T05:57:43.622718Z","shell.execute_reply":"2024-12-21T05:57:43.621786Z","shell.execute_reply.started":"2024-12-21T05:57:43.606614Z"},"trusted":true},"outputs":[],"source":["model.compile(loss = \"categorical_crossentropy\" , metrics = [\"accuracy\"])"]},{"cell_type":"markdown","metadata":{},"source":["Data Augmentation"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.624283Z","iopub.status.busy":"2024-12-21T05:57:43.623954Z","iopub.status.idle":"2024-12-21T05:57:43.630050Z","shell.execute_reply":"2024-12-21T05:57:43.629196Z","shell.execute_reply.started":"2024-12-21T05:57:43.624248Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","    rotation_range=10,  # randomly rotate images \n","    zoom_range=0.1,  # Randomly zoom image\n","    width_shift_range=0.1,  # randomly shift images horizontally \n","    height_shift_range=0.1,  # randomly shift images vertically \n","    horizontal_flip=True,  # randomly flip images horizontally\n","    vertical_flip=False) "]},{"cell_type":"markdown","metadata":{},"source":["Load Dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:43.631769Z","iopub.status.busy":"2024-12-21T05:57:43.631235Z","iopub.status.idle":"2024-12-21T05:57:51.682666Z","shell.execute_reply":"2024-12-21T05:57:51.681659Z","shell.execute_reply.started":"2024-12-21T05:57:43.631716Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 19526 images belonging to 18 classes.\n","Found 19526 images belonging to 18 classes.\n"]}],"source":["train_it = datagen.flow_from_directory(r'C:\\Users\\acer\\Downloads\\dataset dummy\\train', \n","                                       target_size=(224, 224), \n","                                       color_mode='rgb', \n","                                       class_mode=\"categorical\")\n","valid_it = datagen.flow_from_directory(r'C:\\Users\\acer\\Downloads\\dataset dummy\\validation', \n","                                      target_size=(224, 224), \n","                                      color_mode='rgb', \n","                                      class_mode=\"categorical\")"]},{"cell_type":"markdown","metadata":{},"source":["Train the Model"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-12-21T05:57:51.685100Z","iopub.status.busy":"2024-12-21T05:57:51.684834Z","iopub.status.idle":"2024-12-21T05:58:10.154539Z","shell.execute_reply":"2024-12-21T05:58:10.152775Z","shell.execute_reply.started":"2024-12-21T05:57:51.685075Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","251/610 [===========>..................] - ETA: 6:34 - loss: 1.4626 - accuracy: 0.6938"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\acer\\Downloads\\rotten-and-fresh-fruit-classifier.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_it,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_it,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mtrain_it\u001b[39m.\u001b[39;49msamples\u001b[39m/\u001b[39;49mtrain_it\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalid_it\u001b[39m.\u001b[39;49msamples\u001b[39m/\u001b[39;49mvalid_it\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/acer/Downloads/rotten-and-fresh-fruit-classifier.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import matplotlib.pyplot as plt\n","history = model.fit(\n","    train_it,\n","    validation_data=valid_it,\n","    steps_per_epoch=train_it.samples/train_it.batch_size,\n","    validation_steps=valid_it.samples/valid_it.batch_size,\n","    epochs=20\n",")\n","\n","\n","# Plot training & validation accuracy values\n","plt.figure(figsize=(12, 6))\n","\n","# Accuracy plot\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='train accuracy')\n","plt.plot(history.history['val_accuracy'], label='validation accuracy')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# Loss plot\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='validation loss')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-12-21T05:58:10.155721Z","iopub.status.idle":"2024-12-21T05:58:10.156286Z","shell.execute_reply":"2024-12-21T05:58:10.156056Z"},"trusted":true},"outputs":[],"source":["model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":46490,"sourceId":84555,"sourceType":"datasetVersion"}],"dockerImageVersionId":30121,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":4}
